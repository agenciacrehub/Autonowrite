#!/usr/bin/env python3
"""
Corre√ß√£o autom√°tica para problema de mem√≥ria no AutonoWrite
"""

import os
import subprocess
import sys
from typing import Optional

def check_system_memory():
    """Verifica mem√≥ria dispon√≠vel do sistema"""
    try:
        if os.name == 'posix':  # Linux/Mac
            result = subprocess.run(['free', '-h'], capture_output=True, text=True)
            print("Mem√≥ria do sistema:")
            print(result.stdout)
        elif os.name == 'nt':  # Windows
            result = subprocess.run(['wmic', 'computersystem', 'get', 'TotalPhysicalMemory'], 
                                  capture_output=True, text=True)
            print("Informa√ß√µes de mem√≥ria do Windows dispon√≠veis via wmic")
    except:
        print("N√£o foi poss√≠vel verificar mem√≥ria automaticamente")

def fix_ollama_memory_issue():
    """Corrige problema de mem√≥ria do Ollama"""
    print("üîß CORRE√á√ÉO DO PROBLEMA DE MEM√ìRIA OLLAMA")
    print("=" * 50)
    
    check_system_memory()
    
    print("\nüìã Solu√ß√µes dispon√≠veis:")
    print("1. Usar modelo menor do Ollama")
    print("2. Mudar para Groq API (gratuita, sem uso de RAM local)")
    print("3. Usar simula√ß√£o (para desenvolvimento)")
    print("4. Liberar mem√≥ria do sistema")
    
    choice = input("\nEscolha a solu√ß√£o (1-4): ").strip()
    
    if choice == "1":
        fix_ollama_model()
    elif choice == "2":
        setup_groq_alternative()
    elif choice == "3":
        setup_simulation_mode()
    elif choice == "4":
        free_system_memory()
    else:
        print("Op√ß√£o inv√°lida")

def fix_ollama_model():
    """Instala modelo menor do Ollama"""
    print("\nüîß Instalando modelo menor...")
    
    # Modelos leves dispon√≠veis
    light_models = [
        ("phi:2.7b", "2.7B par√¢metros - ~1.5GB RAM"),
        ("gemma:2b", "2B par√¢metros - ~1.3GB RAM"),
        ("tinyllama", "1.1B par√¢metros - ~700MB RAM"),
        ("orca-mini", "3B par√¢metros - ~1.9GB RAM")
    ]
    
    print("\nModelos leves dispon√≠veis:")
    for i, (model, desc) in enumerate(light_models, 1):
        print(f"{i}. {model} - {desc}")
    
    model_choice = input(f"\nEscolha modelo (1-{len(light_models)}): ").strip()
    
    try:
        model_idx = int(model_choice) - 1
        if 0 <= model_idx < len(light_models):
            model_name = light_models[model_idx][0]
            
            print(f"\nüì• Baixando {model_name}...")
            result = subprocess.run(['ollama', 'pull', model_name], 
                                  capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"‚úÖ {model_name} instalado com sucesso!")
                update_main_py_ollama_model(model_name)
            else:
                print(f"‚ùå Erro ao instalar: {result.stderr}")
        else:
            print("N√∫mero inv√°lido")
    except ValueError:
        print("Entrada inv√°lida")

def setup_groq_alternative():
    """Configura alternativa com Groq"""
    print("\nüöÄ CONFIGURA√á√ÉO GROQ (RECOMENDADA)")
    print("-" * 40)
    
    print("Vantagens da Groq:")
    print("‚úÖ Sem uso de RAM local")
    print("‚úÖ Muito mais r√°pida que Ollama")
    print("‚úÖ 15,000 tokens/dia gratuitos")
    print("‚úÖ Qualidade alta (Llama 3)")
    
    print("\nüìã Passos:")
    print("1. Acesse: https://console.groq.com/")
    print("2. Cadastre-se gratuitamente")
    print("3. Crie uma API key")
    print("4. Cole a chave abaixo")
    
    api_key = input("\nCole sua GROQ_API_KEY (ou Enter para pular): ").strip()
    
    if api_key:
        # Atualiza arquivo .env
        env_content = f"GROQ_API_KEY={api_key}\n"
        
        if os.path.exists('.env'):
            with open('.env', 'r') as f:
                existing = f.read()
            if 'GROQ_API_KEY' not in existing:
                env_content = existing + env_content
        
        with open('.env', 'w') as f:
            f.write(env_content)
        
        print("‚úÖ GROQ_API_KEY salva no arquivo .env")
        
        # Testa conex√£o
        test_groq_connection(api_key)
    else:
        print("‚ö†Ô∏è Configure a API key manualmente depois")
        print("üìù Edite o arquivo .env e adicione: GROQ_API_KEY=sua_chave")

def test_groq_connection(api_key: str):
    """Testa conex√£o com Groq"""
    try:
        print("\nüîç Testando conex√£o com Groq...")
        
        # Importa e testa
        sys.path.append('.')
        from main import LLMProvider
        
        llm = LLMProvider("groq")
        response = llm.generate("Responda apenas: OK", max_tokens=10)
        
        if "OK" in response or len(response) > 0:
            print("‚úÖ Groq funcionando perfeitamente!")
            print(f"üìù Resposta de teste: {response[:100]}")
            return True
        else:
            print("‚ö†Ô∏è Resposta inesperada de Groq")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro ao testar Groq: {e}")
        return False

def setup_simulation_mode():
    """Configura modo simula√ß√£o"""
    print("\nüé≠ CONFIGURA√á√ÉO MODO SIMULA√á√ÉO")
    print("-" * 40)
    
    print("Vantagens da simula√ß√£o:")
    print("‚úÖ Sem uso de internet")
    print("‚úÖ Sem limites de uso")
    print("‚úÖ Perfeito para desenvolvimento")
    print("‚úÖ Testa l√≥gica do sistema")
    
    print("\nDesvantagens:")
    print("‚ùå Conte√∫do fict√≠cio")
    print("‚ùå N√£o adequado para resultados finais do TCC")
    
    # Atualiza configura√ß√£o
    update_main_py_provider("simulation")
    print("\n‚úÖ Modo simula√ß√£o ativado")
    print("üí° Para usar APIs reais depois, execute este script novamente")

def free_system_memory():
    """Orienta√ß√µes para liberar mem√≥ria"""
    print("\nüßπ LIBERANDO MEM√ìRIA DO SISTEMA")
    print("-" * 40)
    
    print("Passos para liberar mem√≥ria:")
    print("\n1. Feche programas desnecess√°rios:")
    print("   - Navegadores web (Chrome, Firefox)")
    print("   - Editores pesados (VSCode, PyCharm)")
    print("   - Aplica√ß√µes de m√≠dia")
    
    print("\n2. Limpe cache do sistema:")
    if os.name == 'posix':
        print("   sudo sync && sudo sysctl vm.drop_caches=3")
    else:
        print("   Use Disk Cleanup ou reinicie o sistema")
    
    print("\n3. Pare outros containers Docker:")
    print("   docker stop $(docker ps -q)")
    
    print("\n4. Reinicie o sistema se necess√°rio")
    
    input("\nPressione Enter ap√≥s liberar mem√≥ria...")
    check_system_memory()

def update_main_py_ollama_model(new_model: str):
    """Atualiza modelo do Ollama no main.py"""
    try:
        if not os.path.exists('main.py'):
            print("‚ùå Arquivo main.py n√£o encontrado")
            return
        
        with open('main.py', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Substitui modelo padr√£o
        old_pattern = 'self.model_name = "llama3:8b"'
        new_pattern = f'self.model_name = "{new_model}"'
        
        if old_pattern in content:
            content = content.replace(old_pattern, new_pattern)
            
            with open('main.py', 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"‚úÖ main.py atualizado para usar {new_model}")
        else:
            print("‚ö†Ô∏è N√£o foi poss√≠vel atualizar automaticamente")
            print(f"üí° Edite manualmente: self.model_name = \"{new_model}\"")
            
    except Exception as e:
        print(f"‚ùå Erro ao atualizar main.py: {e}")

def update_main_py_provider(provider: str):
    """Atualiza provider padr√£o no main.py"""
    try:
        if not os.path.exists('main.py'):
            print("‚ùå Arquivo main.py n√£o encontrado")
            return
        
        with open('main.py', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Substitui provider na fun√ß√£o main()
        old_pattern = 'llm = LLMProvider("auto")'
        new_pattern = f'llm = LLMProvider("{provider}")'
        
        if old_pattern in content:
            content = content.replace(old_pattern, new_pattern)
            
            with open('main.py', 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"‚úÖ main.py atualizado para usar provider '{provider}'")
        else:
            print("‚ö†Ô∏è N√£o foi poss√≠vel atualizar automaticamente")
            print(f"üí° Edite manualmente: llm = LLMProvider(\"{provider}\")")
            
    except Exception as e:
        print(f"‚ùå Erro ao atualizar main.py: {e}")

def quick_test_system():
    """Teste r√°pido do sistema ap√≥s corre√ß√£o"""
    print("\nüß™ TESTE R√ÅPIDO DO SISTEMA")
    print("-" * 30)
    
    try:
        sys.path.append('.')
        from main import AutonoWriteSystem, LLMProvider
        
        # Testa provider configurado
        llm = LLMProvider("auto")
        print(f"‚úÖ Provider ativo: {llm.provider_type}")
        
        if llm.provider_type == "ollama":
            print("‚ö†Ô∏è Ainda usando Ollama - pode ter problemas de mem√≥ria")
            print("üí° Considere usar Groq ou simula√ß√£o")
        
        # Teste muito b√°sico
        system = AutonoWriteSystem(llm)
        print("‚úÖ Sistema AutonoWrite inicializado")
        
        print("\nüéØ Sistema pronto para uso!")
        print("Execute: python main.py")
        
    except Exception as e:
        print(f"‚ùå Sistema ainda com problemas: {e}")
        print("üí° Execute as corre√ß√µes sugeridas acima")

if __name__ == "__main__":
    try:
        fix_ollama_memory_issue()
        quick_test_system()
        
        print("\n" + "=" * 50)
        print("‚úÖ CORRE√á√ÉO CONCLU√çDA")
        print("=" * 50)
        print("Pr√≥ximos passos:")
        print("1. Execute: python main.py")
        print("2. Teste gera√ß√£o de conte√∫do")
        print("3. Se houver problemas, execute este script novamente")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Corre√ß√£o interrompida")
    except Exception as e:
        print(f"\n‚ùå Erro na corre√ß√£o: {e}")